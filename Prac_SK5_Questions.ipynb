{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Exercise: Scikit-Learn 5\n",
    "### Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "As part of the [SK5 Tutorial](https://www.featureranking.com/tutorials/machine-learning-tutorials/sk-part-5-advanced-topics-pipelines-statistical-model-comparison-and-model-deployment/), the objective of this practice notebook is to illustrate how you can set up `pipelines` for streamlining your machine learning workflow using `Scikit-Learn`. Pipelines make life easier in relatively large machine learning projects by combining multiple steps in to a single process.\n",
    "\n",
    "You will be using the cleaned \"income data\" dataset. In the previous practices, you cleaned and transformed the raw `income data` and renamed the `income` column as `target` (with high income being the positive class). Including `target`, the cleaned data consists of 42 columns and 45,222 rows. Each column is numeric and between 0 and 1.\n",
    "\n",
    "You will use **stratified 5-fold cross-validation with no repetitions** during training. For testing, you will use the fine-tuned model for prediction **without** any cross-validation for simplicity.\n",
    "\n",
    "In `GridSearchCV()`, try setting `n_jobs` to -2 for shorter run times with parallel processing. Here, -2 means use all core except 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 0: Modeling Preparation\n",
    "\n",
    "- Read in the clean data `us_census_income_data_clean_encoded.csv` on GitHub [here](https://github.com/vaksakalli/datasets). \n",
    "- Randomly sample 5000 rows using a random seed of 999.\n",
    "- Split the sampled data as 70% training set and the remaining 30% test set using a random seed of 999. \n",
    "- Remember to separate `target` during the splitting process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Pipeline Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For feature selection, you will use the powerful Random Forest Importance (RFI) method with 100 estimators. A trick here is that you will need a bit of coding so that you can make RFI feature selection as part of the pipeline. For this reason, we are providing for you the custom `RFIFeatureSelector()` class below to pass in RFI as a \"step\" to the pipeline.\n",
    "```Python\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# custom function for RFI feature selection inside a pipeline\n",
    "# here we use n_estimators=100\n",
    "# notice the random_state in RandomForestClassifier()\n",
    "# to control randomness\n",
    "class RFIFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    # class constructor \n",
    "    # make sure class attributes end with a \"_\"\n",
    "    # per scikit-learn convention to avoid errors\n",
    "    def __init__(self, n_features_=10):\n",
    "        self.n_features_ = n_features_\n",
    "        self.fs_indices_ = None\n",
    "    # override the fit function\n",
    "    def fit(self, X, y):\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from numpy import argsort\n",
    "        model_rfi = RandomForestClassifier(n_estimators=100, random_state=999)\n",
    "        model_rfi.fit(X, y)\n",
    "        self.fs_indices_ = argsort(model_rfi.feature_importances_)[::-1][0:self.n_features_] \n",
    "        return self \n",
    "    # override the transform function\n",
    "    def transform(self, X, y=None):\n",
    "        return X[:, self.fs_indices_]\n",
    "```\n",
    "\n",
    "We are also making available the custom function below, called `get_search_results()`, which will format outputs of an input grid search object as a `Pandas` data frame.\n",
    "```Python\n",
    "# custom function to format the search results as a Pandas data frame\n",
    "def get_search_results(gs):\n",
    "    def model_result(scores, params):\n",
    "        scores = {'mean_score': np.mean(scores),\n",
    "             'std_score': np.std(scores),\n",
    "             'min_score': np.min(scores),\n",
    "             'max_score': np.max(scores)}\n",
    "        return pd.Series({**params,**scores})\n",
    "    models = []\n",
    "    scores = []\n",
    "    for i in range(gs.n_splits_):\n",
    "        key = f\"split{i}_test_score\"\n",
    "        r = gs.cv_results_[key]        \n",
    "        scores.append(r.reshape(-1,1))\n",
    "    all_scores = np.hstack(scores)\n",
    "    for p, s in zip(gs.cv_results_['params'], all_scores):\n",
    "        models.append((model_result(s, p)))\n",
    "    pipe_results = pd.concat(models, axis=1).T.sort_values(['mean_score'], ascending=False)\n",
    "    columns_first = ['mean_score', 'std_score', 'max_score', 'min_score']\n",
    "    columns = columns_first + [c for c in pipe_results.columns if c not in columns_first]\n",
    "    return pipe_results[columns]\n",
    "```\n",
    "\n",
    "You will need to copy and paste these two code blocks before you can continue with the next exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Using a pipeline, stack Random Forest Importance (RFI) feature selection together with grid search for DT hyperparameter tuning via cross-validation using the **train** data. For scoring, use AUC, that is, \"area under the ROC curve\". \n",
    "\n",
    "For RFI, consider number of features in {10, 20, full_number_of_descriptive_features}.\n",
    "\n",
    "For the DT model, aim to determine the optimal combinations of maximum depth (`max_depth`) and minimum sample split (`min_samples_split`) using the **Gini Index** split criterion. In particular, consider max_depth values in {3, 5, 7, 9, 11} and min_samples_split values in {2, 5, 7, 9, 11}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Display the pipeline best parameters, the best score, and the best estimator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Using the custom `get_search_results()` function, display the top 5 combinations of the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Visualize DT performance comparison results by filtering the output of the `get_search_results()` function for 10 features. Put minimum samples for split in the x-axis, AUC in the y-axis and break down the plot by maximum depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "Using the best estimator of the pipeline, obtain the predictions on the **test** data. Display the confusion matrix and the AUC score on this test data. \n",
    "\n",
    "Next, using the best estimator of the pipeline, obtain the predictions on the **train** data. Display the confusion matrix and the AUC score on this train data. \n",
    "\n",
    "How does the test AUC compare to the train AUC? Why do you think there is difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "www.featureranking.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
