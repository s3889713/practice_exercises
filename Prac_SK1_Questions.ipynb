{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Practice Exercise: Scikit-Learn 1\n",
    "## Basic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Objectives\n",
    "\n",
    "In line with the [SK1 Tutorial](https://www.featureranking.com/tutorials/machine-learning-tutorials/sk-part-1-basic-modeling/), the objective of this practice notebook is to familiarize you with working with a regression problem using a `holdout` approach. The dataset under consideration is the `diamonds` dataset that comes with the `ggplot2` library in R.\n",
    "\n",
    "The `diamonds` dataset contains information on diamonds including carat (numeric), clarity (categorical), cut (categorical), and color (categorical). The dataset has 10 features and 53940 instances. The objective is to predict the price of a diamond in USD given its attributes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise 0: Data Preparation\n",
    "\n",
    "Prepare the dataset for predictive modeling as follows:\n",
    "\n",
    "0. Refer to our data prep practice solutions on Canvas as well as our data prep script on GitHub [here](https://github.com/vaksakalli/datasets/blob/master/prepare_dataset_for_modeling.py) for some inspiration on preparing this data for predictive modeling.\n",
    "1. Set `pd.set_option('display.max_columns', None)`. Read in the raw data `diamonds.csv` on GitHub [here](https://github.com/vaksakalli/datasets). Have a look at the shape and data types of the features. Also have a look at the top 5 rows.\n",
    "2. Generate descriptive statistics for categorical and numerical features separately.\n",
    "3. Have a look at the unique values for each categorical feature and check whether everything is OK in the sense that there are no unusual values.\n",
    "4. Make sure there are no missing values anywhere.\n",
    "5. Separate the last column from the dataset and set it to \"target\". Make sure \"target\" is a `Pandas` series at this point, and not a `NumPy` array (which will be necessary for the sampling below). Set all the other columns to be the \"Data\" data frame, which will be the set of descriptive features.\n",
    "6. Make sure all categorical descriptive features are encoded via one-hot-encoding. In this particular dataset, some categorical descriptive features are actually ordinal, but we will go ahead and encode them via one-hot-encoding for simplicity.\n",
    "7. Make sure all descriptive features are scaled via min-max scaling and the output is a `Pandas` data frame with correct column names. Do **NOT** scale the target feature!\n",
    "8. Finally have a look at the top 5 rows of \"target\" and \"Data\" respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise 1: Modeling Preparation\n",
    "\n",
    "- Randomly sample 5000 rows as it's too big for a short demo (using a random seed of 999). Make sure to run `reset_index(drop=True)` on the sampled data to reset the indices.\n",
    "> - **NOTE:** It's **extremely** important to use the same seed for both Data and target while sampling, otherwise you will happily mix and match different rows without getting any execution errors and all you results will be garbage.\n",
    "- Split the sampled data as 70% training set and the remaining 30% test set using a random seed of 999. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "- Fit a nearest neighbor (NN) regressor with $k=3$ neighbors using the Euclidean distance. \n",
    "- Fit the model on the train data and evaluate its $R^2$ (the default \"score()\" for regressors) performance on the test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "- Extend Question 2 by fitting $k=1,\\ldots,10$ neighbors using the Manhattan and Euclidean distances respectively.\n",
    "- What is the optimal $k$ value for each distance metric? That is, at which $k$, the NN regressor returns the highest $R^2$ score?\n",
    "- Which distance metric seems to be better? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "- Fit a decision tree regressor with default values on the train data, and then evaluate its performance on the test data. \n",
    "- Does it perform better than the best KNN model from the previous question?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "- Fit a simple linear regression model on train data, and then evaluate its performance on the test data. **Hint:** Use `LinearRegression()` in `sklearn.linear_model`. \n",
    "- How does it compare to the previous models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "- Fit a random forest regressor with `n_estimators=100` on train data, and then evaluate its performance on the test data. \n",
    "- How does it compare to the previous models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "- Predict the first 5 observations of the **test** data using the linear regression model you built earlier. \n",
    "- Display your results as a data frame with three columns: 'target', 'prediction', 'absolute_diff'.\n",
    "- How do the predictions look?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Further exposition**\n",
    "\n",
    "Let's create histograms to visualize the difference between predicted values from the linear regression and target values on both training and test sets. How are the difference values distributed? Are they centered around zero? What are minimum and maximum difference values for training and test sets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: diagnostic of regressors \n",
    "\n",
    "Relying on $R^{2}$ to evaluate regressor performance is not sufficient. Sometimes, we need to ensure if the regressors generate reasonable predictions. In this case, we have to check if the predicted diamond prices are positive (a negative price would imply you would get the diamond free and some extra cash!) \n",
    "\n",
    "Let's predict on training set for each model developed in the previous exercises. Create a dataframe, named `pred_result`, which consists of four columns corresponding to their predictions. Then, run `pred_result.describe()` to check if any model has a negative minimum value. Does the result surprise you? Will you get a similar result if you predict on test set?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "www.featureranking.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
